# Federated_learning for anomaly detection on healthcare network traffic data - A snowflake integrated approach.

## Business Understanding:
The goal of this project was to explore the potential of Federated Learning (FL) for enhancing cybersecurity within the Internet of Healthcare Things (IoHT) ecosystem. IoHT refers to a network of connected medical devices that collect, share, and analyze sensitive health data, which improves patient care but also introduces a significant vulnerability to cyberattacks. The specific challenge was to create a scalable and privacy-preserving framework that could detect anomalies—indicating potential cyber threats—without violating data privacy laws like GDPR and HIPAA. The reason for selecting this analysis was clear that healthcare is increasingly reliant on connected devices, but traditional security methods are becoming ineffective in protecting decentralized systems like IoHT. Federated Learning offers a way to address these challenges by allowing decentralized machine learning, enabling each device to locally train models while sharing only the parameters (not the raw data). I aimed to understand how this approach could be used to secure healthcare environments, particularly given the sensitive nature of healthcare data and the strict regulations in place.

One of the main challenges I faced was the heterogeneity of the devices and the data they generate. IoHT devices vary significantly in terms of their computational capabilities and the types of data they produce. Managing this variability while ensuring accurate and generalizable model performance was difficult. Another challenge was ensuring scalability while maintaining a high level of security—something I addressed by integrating the Snowflake cloud platform to manage model updates securely.

Through this project, I gained deeper insights into the balance between security, scalability, and privacy, particularly in a field as sensitive as healthcare. Despite the challenges, this project helped lay the groundwork for future research into how Federated Learning can be applied to various industries, not just healthcare, to address similar security concerns.


## Data Understanding

For this project, I used the ECU-IoHT dataset, which is specifically designed for analyzing cyberattacks in the Internet of Healthcare Things (IoHT) environment. This dataset was chosen because it provides realistic network traffic data generated by connected medical devices, including both normal operations and various types of attacks. It contains key features such as protocols, packet lengths, source and destination addresses, and different types of cyberattacks like Nmap, DoS (Denial of Service), SMURF, and ARP Spoofing. I selected this dataset because it closely simulates the real-world environment in which IoHT devices operate, making it highly relevant for developing and testing the anomaly detection framework. The dataset’s structure allowed me to train local models on different devices, mimicking the distributed nature of healthcare IoT systems while maintaining privacy. Its variety of features also provided a rich set of attributes for identifying attack patterns.

One of the main challenges with the dataset was its heterogeneity, as each connected device in a healthcare system may generate data with slightly different structures. To manage this, I used stratified splitting to ensure that each subset of the data represented the distribution of attack types accurately, which helped prevent data imbalance from skewing model performance. I also applied feature selection and engineering techniques to focus on key features that contribute most to identifying attack types.

## Experimental analysis, Results, and Future Works are clearly mentioned in detail in the attached project paper.

## Technologies used in the project
This project involved several cutting-edge tools and technologies to implement the federated learning framework, handle data, and develop a user-friendly application. Below is a list of the technologies used for this project.

### Programming Languages:
Python - The primary programming language used for model development, data preprocessing, and implementation of the federated learning framework.
SQL - Utilized to interact with the Snowflake database for data querying and storage.

### Machine Learning & Deep Learning Libraries:
TensorFlow - Used for building, training, and managing neural network models in a federated learning setup.
Keras - Utilised the Keras API to define and fine-tune the machine learning models within TensorFlow.
scikit-learn - Used for preprocessing, model evaluation, and machine learning tasks like feature engineering and stratified splitting.

### Data Handling & Analysis:
Pandas - Essential for data manipulation, cleaning, and analysis, providing an easy way to manage large datasets.
NumPy - Used for numerical operations and handling large arrays of data.

### Cloud Platform:
Snowflake - A cloud-based data platform used for securely storing and aggregating model updates, managing client data, and handling large datasets in a scalable and secure manner.
Snowpark (Snowflake Python Library) - Used to establish a session and communicate with Snowflake, facilitating the storage and retrieval of data and models.

### Web Application Development:
Streamlit - A framework used to develop an interactive web application where users could interact with the federated learning system, visualize model performance, and monitor predicted attack types.

### Visualization Tools:
Matplotlib - A Python plotting library used to create visualizations, including confusion matrices, feature importance graphs, and charts showing the distribution of attack predictions.
Seaborn - Complementary to Matplotlib, used for creating enhanced data visualizations and statistical graphics.

### Version Control & Collaboration:
Git/GitHub - Used for version control and collaboration, ensuring that the project files, code, and documentation were properly tracked and managed throughout the development process.

### Data Compression and Storage:
Gzip - Utilized for compressing and decompressing model files (such as HDF5 and JSON files) before storing or retrieving them from Snowflake.
HDF5 Format - Used for storing model weights and parameters after training, particularly for large model files.

### Development & Debugging Tools:

Jupyter Notebook - Used during the initial phases of development for experimenting with data preprocessing, model training, and evaluation.
Overleaf (LaTeX) - Used for writing and formatting the dissertation, ensuring academic quality in documentation.

By utilizing this wide range of technologies, I was able to build a scalable and privacy-preserving framework for anomaly detection in healthcare networks, showcasing my ability to work with advanced tools in data science, machine learning, and cloud-based architectures.
